#include "oneflow/cambricon/kernels/adam_update_kernel_util.h"


namespace oneflow {

#define OF_DEVICE_FUNC __mlu_func__ inline


__mlu_func__ inline float CastScaleRegularizeGradient(
  float model_diff_nram, 
  float model_nram, 
  float scale, 
  float l1, 
  float l2) {
  // model_diff * scale + l1 * ((model >= 0) - (model <= 0)) + l2 * model;
  return model_diff_nram * scale + l1 * ((model_nram >= 0) - (model_nram <= 0)) + l2 * model_nram;
};

#define REM_FOR_STACK (128 * 1024)
#if __BANG_ARCH__
#define MAX_NRAM_SIZE (__MLU_NRAM_SIZE__ * 1024 - REM_FOR_STACK)
#else
#define MAX_NRAM_SIZE (384 * 1024)
#endif

#define SIZE_PER_REGION_ADAM MAX_NRAM_SIZE / 8

__mlu_global__ void AdamUpdateMlu(cnrtDataType_t cnrt_type, int64_t n, float scale, float l1, float l2, float beta1, float beta2,
                              float epsilon, float weight_decay, bool amsgrad,
                              bool do_bias_correction, float learning_rate_val, float lr_scale,
                              float bias_correction1_val, float bias_correction2_val,
                              const float* learning_rate, const float* scale_by_ptr,
                              const int64_t* skip_if, const float* bias_correction1_ptr,
                              const float* bias_correction2_ptr, const float* model_diff, float* model,
                              float* m, float* v, float* max_v) {
  if (skip_if != nullptr && *skip_if != 0) { return; }
  if (learning_rate != nullptr) { learning_rate_val = *learning_rate; }
  if (scale_by_ptr != nullptr) { scale *= *scale_by_ptr; }
  if (bias_correction1_ptr != nullptr) { bias_correction1_val = *bias_correction1_ptr; }
  if (bias_correction2_ptr != nullptr) { bias_correction2_val = *bias_correction2_ptr; }

  learning_rate_val *= lr_scale;
  
  __nram__ float model_diff_nram[SIZE_PER_REGION_ADAM/4];
  __nram__ float model_nram[SIZE_PER_REGION_ADAM/4];
  __nram__ float m_nram[SIZE_PER_REGION_ADAM/4];
  __nram__ float v_nram[SIZE_PER_REGION_ADAM/4];
  int dtype_size = sizeof(float);

  // __bang_printf("SIZE_PER_REGION_ADAM:%d", SIZE_PER_REGION_ADAM);
      
  if(cnrt_type == CNRT_FLOAT32){
    for(int i=taskId; i<n; i+=taskDim) {
      // Copy host memory to nram
      __memcpy(model_diff_nram+i, model_diff+i, dtype_size, GDRAM2NRAM);
      __memcpy(model_nram+i, model+i, dtype_size, GDRAM2NRAM);
      __memcpy(m_nram+i, m+i, dtype_size, GDRAM2NRAM);
      __memcpy(v_nram+i, v+i, dtype_size, GDRAM2NRAM);

      // AdamUpdateFunctor
      const float model_val = model_nram[i];
      float model_diff_t = CastScaleRegularizeGradient(model_diff_nram[i], model_val, scale, l1, l2);

      const float next_m = beta1 * m_nram[i] + (1 - beta1) * model_diff_t;
      m_nram[i] = next_m;

      const  float next_v = beta2 * v_nram[i] + (1 - beta2) * model_diff_t * model_diff_t;
      v_nram[i] = next_v;

      float denom = 0;
      denom = (sqrt(next_v) / sqrt(bias_correction2_val)) + epsilon;
      const float step_size = learning_rate_val / bias_correction1_val;
      model_nram[i] = model_val - step_size * (next_m / denom) - learning_rate_val * weight_decay * model_val;

      // Copy nram memory to host
      __memcpy(model+i, model_nram+i, dtype_size, NRAM2GDRAM);
      __memcpy(m+i, m_nram+i, dtype_size, NRAM2GDRAM);
      __memcpy(v+i, v_nram+i, dtype_size, NRAM2GDRAM);

    }
  } else if(cnrt_type == CNRT_FLOAT16){
    // TODO
  }


}

void AdamUpdateKernelUtil(
    cnrtQueue_t queue, 
    cnrtDim3_t k_dim,
    cnrtFunctionType_t k_type,
    cnrtDataType_t cnrt_type,
    int64_t n, float scale, float l1, float l2, float beta1, float beta2,
    float epsilon, float weight_decay, bool amsgrad, bool do_bias_correction,
    float learning_rate_val, float lr_scale, float bias_correction1_val, float bias_correction2_val,
    const float* learning_rate, const float* scale_by_ptr, const int64_t* skip_if,
    const float* bias_correction1_ptr, const float* bias_correction2_ptr, const float* model_diff, 
    float* model, float* m, float* v, float* max_v) {
  AdamUpdateMlu<<<k_dim, k_type, queue>>>(
      cnrt_type, n, scale, l1, l2, beta1, beta2, epsilon, weight_decay, amsgrad, do_bias_correction,
      learning_rate_val, lr_scale, bias_correction1_val, bias_correction2_val, learning_rate,
      scale_by_ptr, skip_if, bias_correction1_ptr, bias_correction2_ptr, model_diff, model,
      m, v, max_v);
}


} //oneflow
