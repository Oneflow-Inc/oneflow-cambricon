/*
Copyright 2020 The OneFlow Authors. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/
#include "oneflow/cambricon/bang/bang_kernels.h"

namespace oneflow {

static constexpr int nram_limit = 32;

template<typename T>
__mlu_func__ void bang_inplace_atomic_add(const T* from, T* to, int64_t length) {
  int64_t nram_limit_bytes = nram_limit * sizeof(T);
  int64_t nram_rest = (length & 0x1F);  // length % nram_limit
  int64_t nram_rest_bytes = nram_rest * sizeof(T);

  __nram__ T nram_buffer[2 * nram_limit];

  T* nram_from = nram_buffer;
  T* nram_dst = nram_buffer + nram_limit;

  int64_t j = 0;
  for (; j < length - nram_limit + 1; j += nram_limit) {
    __memcpy_async(nram_from, from + j, nram_limit_bytes, GDRAM2NRAM);
    __sync_copy_dram_to_nram();
    __bang_atomic_add(nram_dst, to + j, nram_from, nram_limit);
    __sync_io();
  }
  if (nram_rest > 0) {
    __memcpy_async(nram_from, from + j, nram_rest_bytes, GDRAM2NRAM);
    __bang_atomic_add(nram_dst, to + j, nram_from, nram_rest);
    __sync_io();
  }
}

template<typename T, typename K>
__mlu_global__ void bang_unsorted_segment_sum_internal(const T* input, int64_t batch, int64_t N,
                                                       int64_t length, const K* segment,
                                                       int64_t segment_size, T* output,
                                                       int64_t offset) {
  int64_t input_spatial_size = segment_size * length;
  int64_t output_spatial_size = N * length;

  for (int64_t i = taskId; i < batch * segment_size; i += taskDim) {
    int64_t batch_idx = i / segment_size;
    int64_t segment_idx = i - batch_idx * segment_size;
    K idx = segment[segment_idx] - offset;

    T* to = output + batch_idx * output_spatial_size + idx * length;
    if (idx >= 0 && idx < N) {
      const T* from = input + batch_idx * input_spatial_size + segment_idx * length;
      bang_inplace_atomic_add<T>(from, to, length);
    }
  }
}

template<typename T, typename K>
void bang_unsorted_segment_sum_kernel(BangHandle& handle, const T* input, int64_t batch, int64_t N,
                                      int64_t length, const K* segment, int64_t segment_size,
                                      T* output, int64_t offset) {
  cnrtDim3_t dim = {handle.nclusters, handle.ncores_per_cluster, 1};
  cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_UNION1;
  bang_unsorted_segment_sum_internal<<<dim, func_type, handle.queue>>>(
      input, batch, N, length, segment, segment_size, output, offset);
}

template<typename K>
void bang_unsorted_segment_sum_half_kernel(BangHandle& handle, const void* input, int64_t batch,
                                           int64_t N, int64_t length, const K* segment,
                                           int64_t segment_size, void* output, int64_t offset) {
  cnrtDim3_t dim = {handle.nclusters, handle.ncores_per_cluster, 1};
  cnrtFunctionType_t func_type = CNRT_FUNC_TYPE_UNION1;
  bang_unsorted_segment_sum_internal<<<dim, func_type, handle.queue>>>(
      static_cast<const half*>(input), batch, N, length, segment, segment_size,
      static_cast<half*>(output), offset);
}

#define INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL_IMPL(T, K)                         \
  template void bang_unsorted_segment_sum_kernel<T, K>(                              \
      BangHandle & handle, const T* input, int64_t batch, int64_t N, int64_t length, \
      const K* segment, int64_t segment_size, T* output, int64_t offset);

#define INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(T)         \
  INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL_IMPL(T, int64_t) \
  INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL_IMPL(T, int32_t) \
  INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL_IMPL(T, uint32_t)

INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(float)
INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(half)
#if (__BANG_ARCH__ >= 591) || (__BANG_ARCH__ == 322) || (__BANG_ARCH__ == 372)
INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(int16_t)
INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(int32_t)
#endif
// INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(int8_t)
// INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(uint8_t)
// INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(uint16_t)
// INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(uint32_t)
// INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL(bool)

#undef INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL
#undef INSTANCE_BANG_UNSORTED_SEGMENT_SUM_KERNEL_IMPL

#define INSTANCE_BANG_UNSORTED_SEGMENT_SUM_HALF_KERNEL(K)                               \
  template void bang_unsorted_segment_sum_half_kernel<K>(                               \
      BangHandle & handle, const void* input, int64_t batch, int64_t N, int64_t length, \
      const K* segment, int64_t segment_size, void* output, int64_t offset);

INSTANCE_BANG_UNSORTED_SEGMENT_SUM_HALF_KERNEL(int64_t)
INSTANCE_BANG_UNSORTED_SEGMENT_SUM_HALF_KERNEL(int32_t)
INSTANCE_BANG_UNSORTED_SEGMENT_SUM_HALF_KERNEL(uint32_t)

#undef INSTANCE_BANG_UNSORTED_SEGMENT_SUM_HALF_KERNEL

}  // namespace oneflow
